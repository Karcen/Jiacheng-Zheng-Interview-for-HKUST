{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c06ec64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Lake Superior - Mean Water Level.csv',\n",
       " \"./St. Mary's River - Flow .csv\",\n",
       " './Lake Michigan and Lake Huron - Mean Water Level.csv',\n",
       " './St. Clair River - Flow .csv',\n",
       " './Lake St. Clair - Mean Water Level.csv',\n",
       " './Detroit River - Flow .csv',\n",
       " './Lake Erie - Mean Water Level.csv',\n",
       " './Niagara River - Flow at Buffalo.csv',\n",
       " './Lake Ontario - Mean Water Level.csv',\n",
       " './Ottawa River - Flow at Carillon.csv',\n",
       " './St. Lawrence River - Flow at Cornwall.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openpyxl import load_workbook  # 导入load_workbook函数\n",
    "import pandas as pd  # 导入pandas库\n",
    "import os  # 导入os库\n",
    "\n",
    "# 加载工作簿\n",
    "workbook_path = r'Problem D Great Lakes.xlsx'  # 指定工作簿路径\n",
    "workbook = load_workbook(workbook_path)  # 使用load_workbook函数加载工作簿\n",
    "\n",
    "# 用于存储生成的CSV文件路径的列表\n",
    "generated_csv_paths = []\n",
    "\n",
    "# 处理每个工作表\n",
    "for sheet_name in workbook.sheetnames:  # 遍历工作簿中的每个工作表名称\n",
    "    # 加载工作表\n",
    "    sheet = workbook[sheet_name]  # 使用工作表名称获取工作表对象\n",
    "    \n",
    "    # 提取第一行作为文件名\n",
    "    filename_row = sheet[1]  # 获取第一行数据\n",
    "    filename = '_'.join([cell.value for cell in filename_row if cell.value is not None]) + '.csv'  # 构建文件名\n",
    "    csv_path = os.path.join('./', filename)  # 构建CSV文件的路径\n",
    "    \n",
    "    # 将工作表转换为DataFrame，跳过第一行（表头）并保留行数从7到30\n",
    "    df = pd.DataFrame(sheet.values)  # 将工作表数据转换为DataFrame\n",
    "    df = df.iloc[6:30]  # 行是从0开始索引的，因此第7行在索引6处\n",
    "    \n",
    "    # 使用工作表的第二行作为列名\n",
    "    df.columns = df.iloc[0]  # 将第二行数据设置为DataFrame的列名\n",
    "    df = df[1:]  # 删除用作表头的行\n",
    "    \n",
    "    # 保存为CSV文件\n",
    "    df.to_csv(csv_path, index=False)  # 将DataFrame保存为CSV文件，不包括索引列\n",
    "    generated_csv_paths.append(csv_path)  # 将生成的CSV文件路径添加到列表中\n",
    "\n",
    "generated_csv_paths  # 显示生成的CSV文件路径列表\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd5fea65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>Jun</th>\n",
       "      <th>Jul</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "      <th>Source</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>183.16</td>\n",
       "      <td>183.08</td>\n",
       "      <td>183.08</td>\n",
       "      <td>183.12</td>\n",
       "      <td>183.16</td>\n",
       "      <td>183.24</td>\n",
       "      <td>183.33</td>\n",
       "      <td>183.31</td>\n",
       "      <td>183.27</td>\n",
       "      <td>183.2</td>\n",
       "      <td>183.15</td>\n",
       "      <td>183.06</td>\n",
       "      <td>Lake Superior - Mean Water Level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>182.98</td>\n",
       "      <td>182.94</td>\n",
       "      <td>182.91</td>\n",
       "      <td>183.01</td>\n",
       "      <td>183.24</td>\n",
       "      <td>183.33</td>\n",
       "      <td>183.36</td>\n",
       "      <td>183.39</td>\n",
       "      <td>183.37</td>\n",
       "      <td>183.3</td>\n",
       "      <td>183.29</td>\n",
       "      <td>183.3</td>\n",
       "      <td>Lake Superior - Mean Water Level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>183.22</td>\n",
       "      <td>183.14</td>\n",
       "      <td>183.11</td>\n",
       "      <td>183.14</td>\n",
       "      <td>183.26</td>\n",
       "      <td>183.31</td>\n",
       "      <td>183.36</td>\n",
       "      <td>183.4</td>\n",
       "      <td>183.42</td>\n",
       "      <td>183.44</td>\n",
       "      <td>183.36</td>\n",
       "      <td>183.26</td>\n",
       "      <td>Lake Superior - Mean Water Level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>183.16</td>\n",
       "      <td>183.07</td>\n",
       "      <td>183.03</td>\n",
       "      <td>183.08</td>\n",
       "      <td>183.18</td>\n",
       "      <td>183.23</td>\n",
       "      <td>183.26</td>\n",
       "      <td>183.29</td>\n",
       "      <td>183.27</td>\n",
       "      <td>183.26</td>\n",
       "      <td>183.23</td>\n",
       "      <td>183.19</td>\n",
       "      <td>Lake Superior - Mean Water Level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>183.14</td>\n",
       "      <td>183.07</td>\n",
       "      <td>183.07</td>\n",
       "      <td>183.13</td>\n",
       "      <td>183.23</td>\n",
       "      <td>183.35</td>\n",
       "      <td>183.4</td>\n",
       "      <td>183.42</td>\n",
       "      <td>183.46</td>\n",
       "      <td>183.47</td>\n",
       "      <td>183.46</td>\n",
       "      <td>183.38</td>\n",
       "      <td>Lake Superior - Mean Water Level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year     Jan     Feb     Mar     Apr     May     Jun     Jul     Aug  \\\n",
       "0  2000  183.16  183.08  183.08  183.12  183.16  183.24  183.33  183.31   \n",
       "1  2001  182.98  182.94  182.91  183.01  183.24  183.33  183.36  183.39   \n",
       "2  2002  183.22  183.14  183.11  183.14  183.26  183.31  183.36   183.4   \n",
       "3  2003  183.16  183.07  183.03  183.08  183.18  183.23  183.26  183.29   \n",
       "4  2004  183.14  183.07  183.07  183.13  183.23  183.35   183.4  183.42   \n",
       "\n",
       "      Sep     Oct     Nov     Dec                            Source  \\\n",
       "0  183.27   183.2  183.15  183.06  Lake Superior - Mean Water Level   \n",
       "1  183.37   183.3  183.29   183.3  Lake Superior - Mean Water Level   \n",
       "2  183.42  183.44  183.36  183.26  Lake Superior - Mean Water Level   \n",
       "3  183.27  183.26  183.23  183.19  Lake Superior - Mean Water Level   \n",
       "4  183.46  183.47  183.46  183.38  Lake Superior - Mean Water Level   \n",
       "\n",
       "   Unnamed: 13  Unnamed: 14  Unnamed: 15  \n",
       "0          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化一个空的DataFrame，用于合并的数据集\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# 循环遍历每个CSV文件的路径，将其追加到合并的DataFrame中\n",
    "for csv_path in generated_csv_paths:  # 遍历生成的CSV文件路径列表\n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv(csv_path)  # 使用pd.read_csv函数读取CSV文件\n",
    "    \n",
    "    # 从文件名中提取标识符（去除“.csv”之前的部分）\n",
    "    identifier = os.path.basename(csv_path).replace('.csv', '')  # 从文件路径中提取文件名，并去除“.csv”\n",
    "    \n",
    "    # 将标识符作为新列添加到DataFrame中\n",
    "    df['Source'] = identifier  # 将标识符添加为名为“Source”的新列\n",
    "    \n",
    "    # 追加到合并的DataFrame中\n",
    "    merged_df = pd.concat([merged_df, df], ignore_index=True)  # 使用pd.concat函数将DataFrame追加到合并的DataFrame中，忽略索引\n",
    "\n",
    "# 显示合并后的DataFrame的一部分以进行验证\n",
    "merged_df.head()  # 显示合并后的DataFrame的前几行数据以验证合并结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e43c6288",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[['Source','Year', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep',\n",
    "       'Oct', 'Nov', 'Dec']].to_csv('data.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d31a186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 重新加载已经清理并存储的合并数据集\n",
    "merged_df_cleaned = pd.read_csv('data.csv', na_values='---')  # 使用pd.read_csv函数重新加载数据集，将'---'替换为NaN\n",
    "\n",
    "# 对于每个 'Source'，将 '---' 替换为 NaN，然后计算每列的均值，排除非数字列如 'Year' 和 'Source'\n",
    "numeric_columns = merged_df_cleaned.select_dtypes(include=['float64', 'int64']).columns.difference(['Year'])  # 选择数值列，排除 'Year' 列\n",
    "\n",
    "# 将 '---' 替换为 NaN 并根据 'Source' 填充均值\n",
    "for source in merged_df_cleaned['Source'].unique():  # 遍历每个 'Source'\n",
    "    # 计算当前 'Source' 的每个数值列的均值，排除NaN值\n",
    "    means = merged_df_cleaned[merged_df_cleaned['Source'] == source][numeric_columns].mean()  # 计算每列的均值\n",
    "    # 使用当前 'Source' 的计算均值来填充NaN值\n",
    "    for column in numeric_columns:  # 遍历数值列\n",
    "        merged_df_cleaned.loc[merged_df_cleaned['Source'] == source, column] = merged_df_cleaned[merged_df_cleaned['Source'] == source][column].fillna(means[column])\n",
    "\n",
    "# 通过检查是否还有 '---' 来验证替换是否成功\n",
    "merged_df_cleaned.isin(['---']).sum().sum()  # 检查是否还有 '---'，如果返回0则表示替换成功\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64c3a058",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_cleaned.to_csv('data.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f874edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca56536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
